{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b79471f8",
   "metadata": {},
   "source": [
    "The initial method for processing exam data involved a four-step process:\n",
    "\n",
    "1. Extracting exams using ChatGPT prompts.\n",
    "2. Grouping the extracted exams through clustering.\n",
    "3. Mapping the clusters to specific skills.\n",
    "4. Assigning skills to actual courses.\n",
    "However, this approach was ultimately rejected due to bad results. \n",
    "\n",
    "Nevertheless, the clusters generated in this process can still be utilized in Notebook 6. While it is possible to run Notebook 4 without the clustering step, I've observed that incorporating the results of clustering leads to better outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8321d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is notebook for clustering exams and mapping those clusters to skills\n",
    "# import libraries\n",
    "import pandas as pd\n",
    "import ast\n",
    "import time\n",
    "from transformers import pipeline\n",
    "model_ckpt = \"papluca/xlm-roberta-base-language-detection\"\n",
    "pipe = pipeline(\"text-classification\", model=model_ckpt) # model which detects language\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0b4aef",
   "metadata": {},
   "source": [
    "# STEP 1 extract exams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ad138910",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use your key and organization credentials. If you do not have free credit from openai anymore, it is not for free.\n",
    "key = \"PUT-YOUR-KEY-HERE\"\n",
    "openai.organization = \"PUT-YOUR-ORG-HERE\"\n",
    "openai.api_key = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30043467",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Approach can be modified in the following ways: 1.can adjust prompt as required\n",
    "# 2. use another chatbot (alternative is given in  notebook 6) \n",
    "# 3. or can use classification model as in notebook 03-b\n",
    "# the ultimate result is a list of exams which are identified from the column Assessment details\n",
    "def ask_chatgpt(question):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        n=1,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an algorithm which extracts assessment type from the text. Types are comma separated, packed in square brackets, Example answer: [written exam, essay]. If information is not given just text: [None]. No additional words allowed.\"},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "        ])\n",
    "\n",
    "    message = response.choices[0]['message']\n",
    "    return message['content']\n",
    "\n",
    "# running the code to extract exam skills\n",
    "for year in range(2007, 2023):\n",
    "    for period in range(4, 6):\n",
    "        ind = str(year)+(\"00\")+str(period)\n",
    "        df = pd.read_csv('all_data_merged/student_courses_%s.csv' %ind) #fixme\n",
    "        \n",
    "        if \"Assessment details\" in df.columns: \n",
    "            for idx, row in df.iterrows():\n",
    "                try:\n",
    "                    if type(df.loc[idx, \"Assessment details\"]) != float and df.loc[idx, \"new\"]:\n",
    "                       smth = []\n",
    "                       s = ask_chatgpt(row[\"Assessment details\"])\n",
    "                       lst = re.findall(r'[^\\[\\],]+', s)\n",
    "                       result = [item.strip() for item in lst if item.strip()]\n",
    "                       smth.extend(result)\n",
    "                       print(idx, str(smth))\n",
    "                       df.loc[idx, 'exam_types_processed'] = str(smth)\n",
    "                       time.sleep(20) # essential to put delay to avoid reaching limit per min (at the time of writing it was 3 prompts per min)\n",
    "                except Exception as e:\n",
    "                    print(e, idx, ind)\n",
    "            df.to_csv('all_data_merged/exam_info_processed_%s.csv' % ind,  encoding='utf-8', index=False)  # fixme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f012ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#small explanation on how the output of chatgpt is parsed\n",
    "s = \"[ mündliche Prüfung, Essay ]\"\n",
    "lst = re.findall(r'[^\\[\\],]+', s)\n",
    "result = [item.strip() for item in lst if item.strip()]\n",
    "print(result)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8b654a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "res ....\n",
    "res.to_csv('exam_types.csv',  encoding='utf-8', index=False)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d158541a",
   "metadata": {},
   "source": [
    "# STEP 2 group exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b8c051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first the exam types are translated, becauase all the pretrained models perform much better in english\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "model_name = \"Helsinki-NLP/opus-mt-de-en\"  # Translation model for German to English\n",
    "translator = pipeline(\"translation\", model=model_name, tokenizer=model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "816b7f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv('exam_types.csv')   # read the distinct exam types from prev step\n",
    "res.set_index(\"0\",inplace=True)\n",
    "dic = res.to_dict()[\"1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "babe28dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nl experimentaldesign\n",
      "fr lesson protocol\n",
      "tr inputreferat\n",
      "ur protocol\n",
      "it colloquium\n",
      "fr exercices\n",
      "hi organic synthesis\n",
      "ur test\n",
      "hi laboratory exam\n",
      "ur research paper\n",
      "nl thesenpapier\n",
      "it perception training\n",
      "tr projektreferat\n",
      "es reflexionspaper\n",
      "ur test paper\n",
      "sw analog retake\n",
      "tr podcast/video\n",
      "ur exposé\n",
      "nl plenardiskussionen\n",
      "ur thematischer essay\n",
      "pt osce exam\n",
      "fr rechercheportfolio\n",
      "pt formativer osce\n",
      "ur input-referat\n",
      "ur academic literature\n",
      "ur aktive partizipation\n",
      "nl practical masterprojekt\n",
      "ur mcq\n",
      "fr quellenanalyse\n",
      "it kritische lektüre\n",
      "ur praktikum\n",
      "it projektproposal\n",
      "ur action learning\n",
      "ur bibliographie\n",
      "ur mc-test\n",
      "ur film analysis\n",
      "hi lehrvideo\n",
      "hi testat\n",
      "hi textkritik\n",
      "ur ethnographic research\n",
      "ru gruppenreferate\n",
      "hi co-referat\n",
      "hi portfoliobericht\n",
      "nl referaten\n",
      "tr diskussion\n",
      "nl semesterplan\n",
      "fr recherche\n",
      "nl ethische argumentation\n",
      "ur korrektur\n",
      "it research diary\n",
      "sw benotung\n",
      "ur übung\n",
      "ur immanent examination\n",
      "ur klausur\n",
      "ur online-klausur\n",
      "sw retake\n",
      "ur written quiz\n",
      "ur ethnographic input\n",
      "fr présentation\n",
      "it proseminar\n",
      "nl reflexionspapier\n",
      "ur praktikumsbericht\n",
      "it stundenprotokoll\n",
      "nl portfolioberichte\n",
      "ur reading scientific paper\n",
      "it exkursionsprotokoll\n",
      "ur reflexiver essay\n",
      "ur seminar\n",
      "pt osce\n",
      "ur essay/referat\n",
      "ur reading seminar\n",
      "ur webinare\n",
      "nl textanalyse\n",
      "fr participation en classe\n",
      "fr analyse\n",
      "ur mc-online-klausur\n",
      "ur thesis paper\n",
      "fr questionnaire\n",
      "hi kommentar\n",
      "ur skid-i interview\n",
      "hi interim exam\n",
      "tr impulsreferat\n",
      "ur colloquium notes\n",
      "fr écriture de travaux\n",
      "it master colloquium\n",
      "it protokoll\n",
      "ur mc\n",
      "ur presentation/written exercise\n",
      "ur mc test\n",
      "hi q&a session\n",
      "sw proseminar paper\n",
      "sw pechakucha presentation\n",
      "it protokolle\n",
      "hi ppt presentation\n",
      "ur quizzes\n",
      "nl exkursionsbericht\n",
      "it masterkolloquium\n",
      "it stundenreflexion\n",
      "ur referat\n",
      "es reflexion\n",
      "ur quiz\n",
      "it respondenz\n",
      "ur referate\n",
      "fr présentations\n",
      "ur mcq exam\n",
      "it mini-recherche\n",
      "ur scientific paper\n",
      "it aktionslernen\n",
      "ur paper\n",
      "it quizz\n",
      "sw jahreskurs\n",
      "ur seminar paper\n",
      "hi scientific essay\n",
      "ur seminar thesis\n",
      "pt audioassessment\n",
      "hi video essay\n",
      "ur online-kurs\n",
      "ur projektseminar\n",
      "ur written seminar paper\n",
      "nl ideenskizzen\n",
      "nl vertiefung\n",
      "ur seminar reading\n",
      "fr présentation orale\n",
      "ur exkursion\n",
      "sw submission\n",
      "hi scientific abstract\n",
      "ur kolloquium\n",
      "ur term paper writing\n",
      "ur mc-klausur\n",
      "pt psychological assessment\n"
     ]
    }
   ],
   "source": [
    "# extract english and german exams\n",
    "en_exams = []\n",
    "de_exams = []\n",
    "rest_exams = []\n",
    "for key, value in dic.items():\n",
    "    if value:\n",
    "        lang = pipe(key)[0][\"label\"]\n",
    "        if lang == \"en\":\n",
    "                en_exams.append(key)\n",
    "        elif lang == \"de\": \n",
    "            de_exams.append(key)\n",
    "        else:\n",
    "            print(lang, key)\n",
    "            rest_exams.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "059e9033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wöchentliche lektüre weekly reading weekly reading\n",
      "schriftliche leistungskontrolle written performance control written performance control\n",
      "anwesenheitspflicht Compulsory status Compulsory status\n",
      "mitarbeit co-operation co-operation\n",
      "online-kurse Online courses Online courses\n",
      "kurzvortrag short presentation short presentation\n",
      "leistung Performance Performance\n",
      "forschungskonzept Research concept Research concept\n",
      "impuls-referat impulse-referat impulse-referat\n",
      "lektüreberichte Reading reports Reading reports\n",
      "take-home aufgaben take-home tasks take-home tasks\n",
      "arbeitsaufträge work orders work orders\n",
      "seminararbeit Seminar work Seminar work\n",
      "schriftliche arbeit written work written work\n",
      "abschlussbericht final report final report\n",
      "begleitende mc-tests Accompanying mc tests Accompanying mc tests\n",
      "schriftlicher bericht in writing in writing\n",
      "seminar-arbeit Seminar work Seminar work\n",
      "proseminar-arbeit proseminar work proseminar work\n",
      "diskussionsbeteiligung Discussing participation Discussing participation\n",
      "take-home prüfung take-home exam take-home exam\n",
      "-auswertung -evaluation -evaluation\n",
      "elektronische klausur Electronic clausage Electronic clausage\n",
      "formative mc-prüfung Formative mc test Formative mc test\n",
      "übungsaufgabe exercise task exercise task\n",
      "zusammenfassung summary summary\n",
      "kleingruppenarbeit small-group work small-group work\n",
      "lehrveranstaltungsbegleitende leistungsüberprüfungen course-accompanying performance reviews course-accompanying performance reviews\n",
      "fallbeispiel case study case study\n",
      "zusatzleistung Additional power Additional power\n",
      "vorträge lectures lectures\n",
      "freitext test free text test free text test\n",
      "schriftlicher test written test written test\n",
      "aktive beteiligungen Active participations Active participations\n",
      "sitzungsmoderation session moderation session moderation\n",
      "mc prüfung mc test mc test\n",
      "schriftlicher beitrag in writing in writing\n",
      "mündliche gruppenpräsentation oral group presentation oral group presentation\n",
      "teilnahme Participation Participation\n",
      "mündliche leistungsüberprüfung oral performance review oral performance review\n",
      "semesterschlussprüfung Final examination Final examination\n",
      "übungsaufgaben Exercise tasks Exercise tasks\n",
      "schriftliche ausarbeitung in writing in writing\n",
      "3d modell 3d model 3d model\n",
      "digitale prüfung digital test digital test\n",
      "fehlerrechnungstest error calculation test error calculation test\n",
      "schriftlich dokumentierte analyse in writing documented analysis in writing documented analysis\n",
      "genaue lektüre Exact reading Exact reading\n",
      "hausarbeit housework housework\n",
      "schriftliche prüfung written examination written examination\n",
      "seminarvortrag Seminar lecture Seminar lecture\n",
      "mündliche präsentation oral presentation oral presentation\n",
      "schriftliche multiple choice-prüfung written multiple choice test written multiple choice test\n",
      "lektionstest The test shall be carried out in accordance with the procedure laid down in Annex I to Regulation (EC) No 1107/2009. The test shall be carried out in accordance with the procedure laid down in Annex I to Regulation (EC) No 1107/2009.\n",
      "übersetzungsaufgabe Translation task Translation task\n",
      "schriftliche rückmeldungen written returns written returns\n",
      "schriftliche übungsaufgabe written exercise task written exercise task\n",
      "leistungsnachweis Proof of performance Proof of performance\n",
      "kurzessay shortssay shortssay\n",
      "openbook-prüfung openbook check openbook check\n",
      "einordnung categorisation categorisation\n",
      "schriftlich in writing in writing\n",
      "kurzessays shortssays shortssays\n",
      "online-prüfung online review online review\n",
      "standortbestimmung location determination location determination\n",
      "abschlussklausur Graduation Graduation\n",
      "regelmäßige teilnahme Regular participation Regular participation\n",
      "masterarbeit masterwork masterwork\n",
      "audioaufnahme Audio recording Audio recording\n",
      "kurzpredigt Short Sermon Short Sermon\n",
      "mc-fragen mc-questions mc-questions\n",
      "aufgaben Tasks Tasks\n",
      "lektüreeindruck reading impression reading impression\n",
      "schriftliche semesteraufgaben written semester tasks written semester tasks\n",
      "erstellung wissenschaftlicher poster the creation of scientific poster the creation of scientific poster\n",
      "schriftliche beiträge written contributions written contributions\n",
      "multiple choice prüfung multiple choice test multiple choice test\n",
      "vortrag presentation presentation\n",
      "wiederholungsprüfung Retaliation test Retaliation test\n",
      "multiple choice-prüfung multiple choice test multiple choice test\n",
      "kurzreferate Short abstracts Short abstracts\n",
      "online prüfung online exam online exam\n",
      "erstbelegung First occupation First occupation\n",
      "semesterendprüfung final semester exam final semester exam\n",
      "erstellung eines ausstellungsposters creation of an exhibition poster creation of an exhibition poster\n",
      "aktive teilnahme Active participation Active participation\n",
      "herbstsemester Autumn semester Autumn semester\n",
      "powerpoint-präsentation powerpoint presentation powerpoint presentation\n",
      "schriftliche auseinandersetzung Written examination Written examination\n",
      "proseminararbeit ii proseminar work ii proseminar work ii\n",
      "abgabe der übungsaufgaben surrender of exercise tasks surrender of exercise tasks\n",
      "minipräsentation minipresentation minipresentation\n",
      "schriftliches paper Paper in writing Paper in writing\n",
      "semesterarbeit Semester work Semester work\n",
      "schriftliche leistung in writing in writing\n",
      "aktive mitarbeit Active cooperation Active cooperation\n",
      "verfassen von lesekarten writing of read cards writing of read cards\n",
      "präsentation Presentation Presentation\n",
      "take-home aufgabe take-home task take-home task\n",
      "empirische arbeit Empirical work Empirical work\n",
      "mündliche mitarbeit Oral cooperation Oral cooperation\n",
      "empirische erhebung empirical survey empirical survey\n",
      "prüfungsanmeldung examination application examination application\n",
      "zusätzliche schriftliche leistung Additional written service Additional written service\n",
      "journalistischer beitrag journalistic contribution journalistic contribution\n",
      "mündliche vorlesungsprüfung Oral lecture test Oral lecture test\n",
      "mündliches referat Oral reference Oral reference\n",
      "verdichtetes analyseprotokoll Condensed analysis protocol Condensed analysis protocol\n",
      "modulprüfung module check module check\n",
      "mitarbeit im blockkurs cooperation in the block course cooperation in the block course\n",
      "arbeitspapieren working papers working papers\n",
      "gruppenprojektarbeit group project work group project work\n",
      "identitätsprüfung von arzneidrogen Identity check of medicinal products Identity check of medicinal products\n",
      "schriftliches examen written exam written exam\n",
      "mündlich Oral Oral\n",
      "zwischenbericht betweenreport betweenreport\n",
      "datenerhebung Data collection Data collection\n",
      "mc-prüfung mc test mc test\n",
      "schriftliche zusammenfassung Written summary Written summary\n",
      "3 leistungsüberprüfungen 3 Performance reviews 3 Performance reviews\n",
      "kurzreferat Short abstract Short abstract\n",
      "lektürestudium Studying in reading Studying in reading\n",
      "präsentationen Presentations Presentations\n",
      "prüfung Test Test\n",
      "proseminararbeit proseminar work proseminar work\n",
      "mündliche teilnahme oral participation oral participation\n",
      "gruppenpräsentation group presentation group presentation\n",
      "diskussionsleitungen Discussion lines Discussion lines\n",
      "mündlicher beitrag Oral contribution Oral contribution\n",
      "schriftliche aufgaben written tasks written tasks\n",
      "lektüre Reading Reading\n",
      "tutorat-besuch tutorat visit tutorat visit\n",
      "abschlusspräsentation final presentation final presentation\n",
      "regelmäßige aktive teilnahme regular active participation regular active participation\n",
      "präsenz Presence Presence\n",
      "grammatikblatt Grammatical sheet Grammatical sheet\n",
      "textvorbereitung text preparation text preparation\n",
      "leistungsüberprüfung Performance review Performance review\n",
      "abhalten einer präsentation holding a presentation holding a presentation\n",
      "schriftliche einzelleistungsnachweise Written proofs of performance Written proofs of performance\n",
      "mündliche klausur Oral clausage Oral clausage\n",
      "praktische masterarbeit practical masterwork practical masterwork\n",
      "lehrveranstaltungsbegleitende leistungsüberprüfung course-accompanying performance review course-accompanying performance review\n",
      "seminar-arbeiten Seminar work Seminar work\n",
      "praktisches masterprojekt practical master project practical master project\n",
      "schriftliche form written form written form\n",
      "übungsklausur Exercise Discuss Exercise Discuss\n",
      "wiederholungsklausur Recovery clause Recovery clause\n",
      "aktive beteiligung Active participation Active participation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kurzpräsentation short presentation short presentation\n",
      "schriftliche übung written exercise written exercise\n",
      "präsenzklausur Presence clause Presence clause\n",
      "mündliche beteiligung Oral participation Oral participation\n",
      "computerunterstützter test computer assisted test computer assisted test\n",
      "kurzbiographie Short biography Short biography\n",
      "wörterblatt Wordsheet Wordsheet\n",
      "studienteilnahme participation in studies participation in studies\n",
      "projektergebnisse project results project results\n",
      "diskussionsleitung Discussion direction Discussion direction\n",
      "besuch aller vorträge visit of all presentations visit of all presentations\n",
      "vortrag/referat lecture/referral lecture/referral\n",
      "abschlusstest Final test Final test\n",
      "reflexionsarbeit Reflexion work Reflexion work\n",
      "forschungsprojektplan research project plan research project plan\n",
      "schriftliche klausur Written clausage Written clausage\n",
      "osce-prüfung osce test osce test\n",
      "gruppenarbeit group work group work\n",
      "schlussprüfung Final verification Final verification\n",
      "schriftliche vorlesungsprüfung written lecture test written lecture test\n",
      "erarbeitung Incorporation Incorporation\n",
      "schriftlicher examen written exam written exam\n",
      "projektgruppenarbeit project group work project group work\n",
      "schreibübung writing exercise writing exercise\n",
      "kurzreferaten Short abstracts Short abstracts\n",
      "elektronische prüfung Electronic test Electronic test\n",
      "sitzungsprotokoll Minutes of the sitting Minutes of the sitting\n",
      "leistungsüberprüfungen Performance checks Performance checks\n",
      "praktischer kompetenznachweis Practical proof of competence Practical proof of competence\n",
      "erstellen einer falldarstellung create a case view create a case view\n",
      "diskussionsbeiträge Discussing contributions Discussing contributions\n",
      "gruppenarbeiten group work group work\n",
      "praktischer test Practical test Practical test\n",
      "offene fragen open questions open questions\n",
      "praktischer teil Practical part Practical part\n",
      "mündliche prüfung oral examination oral examination\n"
     ]
    }
   ],
   "source": [
    "# translate the exams\n",
    "translated = [] \n",
    "translated_2 = {}\n",
    "for el in de_exams:\n",
    "    translated_text = translator(el, max_length=40)[0]['translation_text']\n",
    "    print(el, translated_text,  translated_text_1)\n",
    "    translated.append(translated_text)\n",
    "    translated_2[el] = translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4fbc193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all the translations in english and exams which were originally in english\n",
    "en_exams = list(en_exams)\n",
    "en_exams.extend(translated)\n",
    "en_exams = list(set(en_exams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1adc0178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(778, 1370)\n"
     ]
    }
   ],
   "source": [
    "# here starts the clustering. The next 3 cells are performing clustering and saving the resulrs in exam_clusters csv\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "ngram_range = (1, 3)  \n",
    "vectorizer = TfidfVectorizer(ngram_range=ngram_range)\n",
    "\n",
    "\n",
    "# Vectorize the strings\n",
    "vectorized_strings = vectorizer.fit_transform(en_exams)\n",
    "print(vectorized_strings.shape)\n",
    "\n",
    "\n",
    "# Perform K-means clustering\n",
    "k = 100 # parameter to tune\n",
    "kmeans = KMeans(n_clusters=k).fit(vectorized_strings)\n",
    "\n",
    "# Get the centroid of each cluster\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# Find the closest exam to each centroid\n",
    "representative_exams = []\n",
    "for centroid in centroids:\n",
    "    closest_exam_idx = np.argmin(np.linalg.norm(vectorized_strings - centroid, axis=1))\n",
    "    closest_exam = en_exams[closest_exam_idx]\n",
    "    representative_exams.append(closest_exam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701e3b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the cluster labels\n",
    "cluster_labels = kmeans.labels_\n",
    "cluster_centroids = kmeans.cluster_centers_\n",
    "\n",
    "# Create a dictionary to store exams for each cluster\n",
    "cluster_exams = {i: [] for i in range(k)}\n",
    "cluster_centroids = {i: [] for i in range(k)}\n",
    "\n",
    "# Iterate over the skills and cluster labels\n",
    "for i, exam in enumerate(en_exams):\n",
    "    cluster = cluster_labels[i]\n",
    "    cluster_exams[cluster].append(exam)\n",
    "\n",
    "# Get the centroids for each cluster\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# Assign the closest exam to each cluster centroid\n",
    "for cluster, centroid in enumerate(centroids):\n",
    "    closest_exam_idx = np.argmin(np.linalg.norm(vectorized_strings - centroid, axis=1))\n",
    "    closest_exam = en_exams[closest_exam_idx]\n",
    "    cluster_centroids[cluster] = closest_exam\n",
    "    \n",
    "english = {}\n",
    "# Print exams and centroids for each cluster\n",
    "for cluster, exams in cluster_exams.items():\n",
    "    print(f\"Cluster {cluster+1} exams:\")\n",
    "    for exam in exams:\n",
    "        print(exam)\n",
    "        english[exam] = cluster_centroids[cluster]\n",
    "    print(\"Centroid:\", cluster_centroids[cluster])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "f22ca88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_english = pd.DataFrame.from_dict(english, orient='index', columns=['Cluster']) # form a datafrane \n",
    "\n",
    "# Add the exams as a separate column\n",
    "df_english['Exam'] = df_english.index\n",
    "\n",
    "# Set the index name\n",
    "df_english.index.name = 'Index'\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "df_english.to_csv('exam_clusters.csv', index=False) # finally save the results\n",
    "\n",
    "# afterwards I opened this file in excel and I did some manual postprocessing, afterwards that was saved as exam_clusters_processed_2\n",
    "# and accessed in notebook 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a1e9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c047f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fa0783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6ab31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is an alternatve clustering method, but Kmean performed a bit better\n",
    "# Initialize TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Vectorize the strings\n",
    "vectorized_strings = vectorizer.fit_transform(en_exams)\n",
    "print(vectorized_strings.shape)\n",
    "\n",
    "# Perform Agglomerative Clustering\n",
    "k = 70  # parameter to tune\n",
    "agg_clustering = AgglomerativeClustering(n_clusters=k).fit(vectorized_strings.toarray())\n",
    "\n",
    "# Get the cluster labels\n",
    "cluster_labels = agg_clustering.labels_\n",
    "\n",
    "# Create a dictionary to store exams for each cluster\n",
    "cluster_exams = {i: [] for i in range(k)}\n",
    "cluster_centroids = {i: [] for i in range(k)}\n",
    "\n",
    "# Iterate over the exams and cluster labels\n",
    "for i, exam in enumerate(en_exams):\n",
    "    cluster = cluster_labels[i]\n",
    "    cluster_exams[cluster].append(exam)\n",
    "\n",
    "# Assign the closest exam to each cluster centroid\n",
    "for cluster in range(k):\n",
    "    cluster_indices = np.where(cluster_labels == cluster)[0]\n",
    "    cluster_vectors = vectorized_strings[cluster_indices].toarray()\n",
    "    centroid = np.mean(cluster_vectors, axis=0)\n",
    "    closest_exam_idx = np.argmin(np.linalg.norm(cluster_vectors - centroid, axis=1))\n",
    "    closest_exam = en_exams[cluster_indices[closest_exam_idx]]\n",
    "    cluster_centroids[cluster] = closest_exam\n",
    "\n",
    "english = {}\n",
    "# Print exams and centroids for each cluster\n",
    "for cluster, exams in cluster_exams.items():\n",
    "    print(f\"Cluster {cluster+1} exams:\")\n",
    "    for exam in exams:\n",
    "        print(exam)\n",
    "        english[exam] = cluster_centroids[cluster]\n",
    "    print(\"Centroid:\", cluster_centroids[cluster])\n",
    "    print() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cd87d2",
   "metadata": {},
   "source": [
    "# STEP 3 exam to skill map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8b7404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part is no longer relevant, because we do not just map cluster to skill anymore\n",
    "# therefore everything below can be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd11870",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('exam_clusters_processed.csv')\n",
    "clusters = list(set(df[\"Cluster\"]))\n",
    "all_skills = pd.read_csv('skills.csv') # fixme\n",
    "all_skills = list(set(all_skills[\"skill\"].tolist()))\n",
    "new = pd.DataFrame(columns=[\"Cluster\", \"Skills\"])\n",
    "for cluster in clusters:\n",
    "    if cluster not in processed:\n",
    "        skills = []\n",
    "        print(\"Cluster:\", cluster)\n",
    "        print(\"Cluster values:\", df[df[\"Cluster\"] == cluster][\"Exam\"].values)\n",
    "        print(\"skills:\", all_skills)\n",
    "\n",
    "        while True:\n",
    "            skill = input(\"Enter a skill (or 0 to move to the next cluster): \")\n",
    "\n",
    "            if skill == '0':\n",
    "                break\n",
    "\n",
    "            skills.append(skill)\n",
    "\n",
    "        new = new.append({\"Cluster\": cluster, \"Skills\": skills}, ignore_index=True)\n",
    "        \n",
    "new.to_csv('clusters_skill_map.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5afec8",
   "metadata": {},
   "source": [
    "# STEP 4 final course to skill map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9bb50f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "cl_exam_map = pd.read_csv('exam_clusters_processed.csv')\n",
    "cl_skill_map = pd.read_csv('clusters_skill_map.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b56250ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_exam_map = cl_exam_map.set_index('Exam')['Cluster'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c54f6629",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_skill_map = cl_skill_map.set_index('Cluster')['Skills'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aa4019ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in cl_skill_map.items():\n",
    "    parsed_list = ast.literal_eval(value)\n",
    "    parsed_list = [string.strip(\"'\") for string in parsed_list]\n",
    "    cl_skill_map[key] = parsed_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d616224",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for year in range(2007, 2023):\n",
    "    for period in range(4, 6):\n",
    "        ind = str(year) + \"00\" + str(period)\n",
    "        df = pd.read_csv('../all_data_merged/exam_info_processed_%s.csv' % ind)\n",
    "        df = df.groupby(\"Awobjid\").apply(lambda x: x.loc[x[\"exam_types_processed\"].str.len().idxmax()])\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        for idx, row in df.iterrows():\n",
    "            parsed_list = ast.literal_eval(df.loc[idx, \"exam_types_processed\"])\n",
    "            skill_list = []\n",
    "            for element in parsed_list:\n",
    "                # translate if necessary\n",
    "                if element in translated_2:\n",
    "                    el = translated_2[element]\n",
    "                else:\n",
    "                    el = element\n",
    "                # access correponding cluster and skills\n",
    "                if el in cl_exam_map and cl_exam_map[el] in cl_skill_map:\n",
    "                         skill_list.extend(cl_skill_map[cl_exam_map[el]])\n",
    "\n",
    "            print(skill_list)\n",
    "            df.loc[idx, \"exam_skills\"] = str(list(set(skill_list)))\n",
    "        df.to_csv('exam_info_result_%s.csv' % ind,  encoding='utf-8', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42c4745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
